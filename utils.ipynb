{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection Over Union (IOU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(a, b):\n",
    "    a_x1, a_y1, a_x2, a_y2 = a\n",
    "    b_x1, b_y1, b_x2, b_y2 = b\n",
    "    \n",
    "    # assert a_x2 > a_x1, 'x cordinates are invalid'\n",
    "    # assert b_x2 > b_x1, 'x cordinates are invalid'\n",
    "    # assert a_y2 > a_y1, 'y cordinates are invalid'\n",
    "    # assert b_y2 > b_y1, 'y cordinates are invalid'\n",
    "    \n",
    "    x_left = max(a_x1, b_x1)\n",
    "    y_top = max(a_y1, b_y1)\n",
    "    \n",
    "    x_right = min(a_x2, b_x2)\n",
    "    y_bottom = min(a_y2, b_y2)\n",
    "    \n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    \n",
    "    area_intersection = (y_bottom - y_top) * (x_right - x_left)\n",
    "    \n",
    "    a_area = (a_x2- a_x1) * (a_y2 - a_y1)\n",
    "    b_area = (b_x2- b_x1) * (b_y2 - b_y1)\n",
    "    \n",
    "    area_union = float(a_area + b_area - area_intersection + 1e-9)\n",
    "    \n",
    "    iou = area_intersection / area_union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_iou([0,3,3,0], [1,1,4,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Maximum Subpression (NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this implimantation is class independent\n",
    "# can be implimented for class agnostic\n",
    "def apply_nms(preds, nms_threshold=0.5):\n",
    "    # preds = [[x1, y1, x2, y2, score], ...]\n",
    "    # sort by confidance socre\n",
    "    preds = sorted(preds, key=lambda k: k[-1])\n",
    "    \n",
    "    # final pred list\n",
    "    keep_pred = []\n",
    "    while len(preds) > 0:\n",
    "        keep_pred.append(preds[0])\n",
    "        preds = [\n",
    "            box for box in preds[1:]\n",
    "            if get_iou(keep_pred[-1][:-1], box[:-1]) < nms_threshold\n",
    "        ]\n",
    "    return keep_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean Average Precision (mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mAP(det_boxes, gt_boxes, iou_threshold=0.5, method='interp'):\n",
    "    r\"\"\"\n",
    "    Method to calculate Mean Average Precision between two sets of boxes.\n",
    "    Each will be a list of dictionary containing predictions/gt for\n",
    "    ALL classes.\n",
    "\n",
    "    :param det_boxes: List[Dict[List[float]]] prediction boxes for ALL images\n",
    "                    det_boxes = [\n",
    "                        {\n",
    "                            'person' : [[x1, y1, x2, y2, score], ...],\n",
    "                            'car' : [[x1, y1, x2, y2, score], ...]\n",
    "                            'class_with_no_detections' : [],\n",
    "                            ...,\n",
    "                            'class_K':[[x1, y1, x2, y2, score], ...]\n",
    "                        },\n",
    "                        {det_boxes_img_2},\n",
    "                         ...\n",
    "                        {det_boxes_img_N},\n",
    "                    ]\n",
    "    :param gt_boxes: List[Dict[List[float]]] ground truth boxes for ALL images\n",
    "                    gt_boxes = [\n",
    "                        {\n",
    "                            'person' : [[x1, y1, x2, y2], ...],\n",
    "                            'car' : [[x1, y1, x2, y2], ...]\n",
    "                            'class_with_no_ground_truth_objects' : [],\n",
    "                            ...,\n",
    "                            'class_K':[[x1, y1, x2, y2], ...]\n",
    "                        },\n",
    "                        {gt_boxes_img_2},\n",
    "                         ...\n",
    "                        {gt_boxes_img_N},\n",
    "                    ]\n",
    "    :param iou_threshold: (float) Threshold used for true positive. Default:0.5\n",
    "    :param method: (str) One of area/interp. Default:interp\n",
    "    :return: mean_ap, all_aps: Tuple(float, Dict[float])\n",
    "                mean_ap is MAP at the provided threshold.\n",
    "                all_aps is ap for all categories\n",
    "    \"\"\"\n",
    "    gt_labels = {cls_key for im_gt in gt_boxes for cls_key in im_gt.keys()}\n",
    "    all_aps = {}\n",
    "    # average precisions for ALL classes\n",
    "    aps = []\n",
    "    for idx, label in enumerate(gt_labels):\n",
    "        # Get detection predictions of this class\n",
    "        cls_dets = [\n",
    "            [im_idx, im_dets_label] for im_idx, im_dets in enumerate(det_boxes)\n",
    "            if label in im_dets for im_dets_label in im_dets[label]\n",
    "        ]\n",
    "        \n",
    "        # cls_dets = [\n",
    "        #   (0, [x1_0, y1_0, x2_0, y2_0, score_0]),\n",
    "        #   ...\n",
    "        #   (0, [x1_M, y1_M, x2_M, y2_M, score_M]),\n",
    "        #   (1, [x1_0, y1_0, x2_0, y2_0, score_0]),\n",
    "        #   ...\n",
    "        #   (1, [x1_N, y1_N, x2_N, y2_N, score_N]),\n",
    "        #   ...\n",
    "        # ]\n",
    "        \n",
    "        # Sort them by confidence score\n",
    "        cls_dets = sorted(cls_dets, key=lambda k: -k[1][-1])\n",
    "        \n",
    "        # For tracking which gt boxes of this class have already been matched\n",
    "        gt_matched = [[False for _ in im_gts[label]] for im_gts in gt_boxes]\n",
    "        # Number of gt boxes for this class for recall calculation\n",
    "        num_gts = sum([len(im_gts[label]) for im_gts in gt_boxes])\n",
    "        tp = [0] * len(cls_dets)\n",
    "        fp = [0] * len(cls_dets)\n",
    "        \n",
    "        # For each prediction\n",
    "        for det_idx, (im_idx, det_pred) in enumerate(cls_dets):\n",
    "            # Get gt boxes for this image and this label\n",
    "            im_gts = gt_boxes[im_idx][label]\n",
    "            max_iou_found = -1\n",
    "            max_iou_gt_idx = -1\n",
    "            \n",
    "            # Get best matching gt box\n",
    "            for gt_box_idx, gt_box in enumerate(im_gts):\n",
    "                gt_box_iou = get_iou(det_pred[:-1], gt_box)\n",
    "                if gt_box_iou > max_iou_found:\n",
    "                    max_iou_found = gt_box_iou\n",
    "                    max_iou_gt_idx = gt_box_idx\n",
    "            # TP only if iou >= threshold and this gt has not yet been matched\n",
    "            if max_iou_found < iou_threshold or gt_matched[im_idx][max_iou_gt_idx]:\n",
    "                fp[det_idx] = 1\n",
    "            else:\n",
    "                tp[det_idx] = 1\n",
    "                # If tp then we set this gt box as matched\n",
    "                gt_matched[im_idx][max_iou_gt_idx] = True\n",
    "        # Cumulative tp and fp\n",
    "        tp = np.cumsum(tp)\n",
    "        fp = np.cumsum(fp)\n",
    "        \n",
    "        eps = np.finfo(np.float32).eps\n",
    "        recalls = tp / np.maximum(num_gts, eps)\n",
    "        precisions = tp / np.maximum((tp + fp), eps)\n",
    "        \n",
    "        if method == 'area':\n",
    "            recalls = np.concatenate(([0.0], recalls, [1.0]))\n",
    "            precisions = np.concatenate(([0.0], precisions, [0.0]))\n",
    "            \n",
    "            # Replace precision values with recall r with maximum precision value\n",
    "            # of any recall value >= r\n",
    "            # This computes the precision envelope\n",
    "            for i in range(precisions.size - 1, 0, -1):\n",
    "                precisions[i - 1] = np.maximum(precisions[i - 1], precisions[i])\n",
    "            # For computing area, get points where recall changes value\n",
    "            i = np.where(recalls[1:] != recalls[:-1])[0]\n",
    "            # Add the rectangular areas to get ap\n",
    "            ap = np.sum((recalls[i + 1] - recalls[i]) * precisions[i + 1])\n",
    "        elif method == 'interp':\n",
    "            ap = 0.0\n",
    "            for interp_pt in np.arange(0, 1 + 1E-3, 0.1):\n",
    "                # Get precision values for recall values >= interp_pt\n",
    "                prec_interp_pt = precisions[recalls >= interp_pt]\n",
    "                \n",
    "                # Get max of those precision values\n",
    "                prec_interp_pt = prec_interp_pt.max() if prec_interp_pt.size > 0.0 else 0.0\n",
    "                ap += prec_interp_pt\n",
    "            ap = ap / 11.0\n",
    "        else:\n",
    "            raise ValueError('Method can only be area or interp')\n",
    "        if num_gts > 0:\n",
    "            aps.append(ap)\n",
    "            all_aps[label] = ap\n",
    "        else:\n",
    "            all_aps[label] = np.nan\n",
    "    # compute mAP at provided iou threshold\n",
    "    mean_ap = sum(aps) / (len(aps) + 1E-6)\n",
    "    return mean_ap, all_aps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
